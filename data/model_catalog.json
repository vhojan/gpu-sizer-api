[
  {
    "Model": "Mistral-7B",
    "Size": "7B",
    "VRAM Required (GB)": 20,
    "Base Latency (s)": 0.9,
    "Parameters": "7B",
    "Weights Size (FP16, GB)": 13.0,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "LLaMA2-13B",
    "Size": "13B",
    "VRAM Required (GB)": 40,
    "Base Latency (s)": 1.2,
    "Parameters": "13B",
    "Weights Size (FP16, GB)": 24.2,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "LLaMA2-70B",
    "Size": "70B",
    "VRAM Required (GB)": 80,
    "Base Latency (s)": 2.5,
    "Parameters": "70B",
    "Weights Size (FP16, GB)": 130.4,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "LLaMA 3-400B (Maverick)",
    "Size": "400B",
    "VRAM Required (GB)": 320,
    "Base Latency (s)": 3.5,
    "Parameters": "400B",
    "Weights Size (FP16, GB)": 745.1,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "GPT-3.5",
    "Size": "175B",
    "VRAM Required (GB)": 200,
    "Base Latency (s)": 2.8,
    "Parameters": "175B",
    "Weights Size (FP16, GB)": 326.0,
    "Architecture": "Unknown",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Claude 3 Opus",
    "Size": "220B",
    "VRAM Required (GB)": 240,
    "Base Latency (s)": 3.0,
    "Parameters": "220B",
    "Weights Size (FP16, GB)": 409.8,
    "Architecture": "Unknown",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Command R+",
    "Size": "35B",
    "VRAM Required (GB)": 60,
    "Base Latency (s)": 1.7,
    "Parameters": "35B",
    "Weights Size (FP16, GB)": 65.2,
    "Architecture": "Decoder-only",
    "Intended Use": "Chat",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Gemma-2B",
    "Size": "2B",
    "VRAM Required (GB)": 6,
    "Base Latency (s)": 0.5,
    "Parameters": "2B",
    "Weights Size (FP16, GB)": 3.7,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Gemma-7B",
    "Size": "7B",
    "VRAM Required (GB)": 20,
    "Base Latency (s)": 0.9,
    "Parameters": "7B",
    "Weights Size (FP16, GB)": 13.0,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Phi-3 Mini (3.8B)",
    "Size": "3.8B",
    "VRAM Required (GB)": 12,
    "Base Latency (s)": 0.6,
    "Parameters": "3.8B",
    "Weights Size (FP16, GB)": 7.1,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Phi-3 Small (7B)",
    "Size": "7B",
    "VRAM Required (GB)": 22,
    "Base Latency (s)": 0.9,
    "Parameters": "7B",
    "Weights Size (FP16, GB)": 13.0,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Phi-3 Medium (14B)",
    "Size": "14B",
    "VRAM Required (GB)": 44,
    "Base Latency (s)": 1.3,
    "Parameters": "14B",
    "Weights Size (FP16, GB)": 26.1,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Mixtral-8x22B",
    "Size": "MoE-8x22B",
    "VRAM Required (GB)": 96,
    "Base Latency (s)": 2.1,
    "Parameters": "MoE-8x22B",
    "Weights Size (FP16, GB)": null,
    "Architecture": "MoE (Mixture of Experts)",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "LLaVA-1.6",
    "Size": "13B",
    "VRAM Required (GB)": 40,
    "Base Latency (s)": 1.4,
    "Parameters": "13B",
    "Weights Size (FP16, GB)": 24.2,
    "Architecture": "Multimodal (Vision + Text)",
    "Intended Use": "Vision + Chat",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "LLaVA-1.8",
    "Size": "34B",
    "VRAM Required (GB)": 68,
    "Base Latency (s)": 2.2,
    "Parameters": "34B",
    "Weights Size (FP16, GB)": 63.3,
    "Architecture": "Multimodal (Vision + Text)",
    "Intended Use": "Vision + Chat",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "LLaMA 3-8B",
    "Size": "8B",
    "VRAM Required (GB)": 26,
    "Base Latency (s)": 0.95,
    "Parameters": "8B",
    "Weights Size (FP16, GB)": 14.9,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "LLaMA 3-70B",
    "Size": "70B",
    "VRAM Required (GB)": 80,
    "Base Latency (s)": 2.4,
    "Parameters": "70B",
    "Weights Size (FP16, GB)": 130.4,
    "Architecture": "Decoder-only",
    "Intended Use": "General",
    "KV Cache (GB per user)": 1.5
  },
  {
    "Model": "Command R+ 104B",
    "Size": "104B",
    "VRAM Required (GB)": 120,
    "Base Latency (s)": 3.1,
    "Parameters": "104B",
    "Weights Size (FP16, GB)": 193.7,
    "Architecture": "Decoder-only",
    "Intended Use": "Chat",
    "KV Cache (GB per user)": 1.5
  }
]